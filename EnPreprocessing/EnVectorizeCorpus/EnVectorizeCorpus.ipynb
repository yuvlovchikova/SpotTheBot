{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87647cf6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d74ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = \"EnCleanCorpus.csv\"\n",
    "WORD_LIST = \"WORD_LIST.npy\"\n",
    "WORD_VECTORS = \"U.npy\"\n",
    "\n",
    "VECTOR_SHAPE = 8\n",
    "SEQUENCE_SHAPE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3698529",
   "metadata": {},
   "source": [
    "# Vectorize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut_dict_values(input_dict: dict, k: int) -> dict:\n",
    "    lambda_ = lambda value: value[:k]\n",
    "    dict_ = dict(zip(input_dict, map(lambda_, input_dict.values())))\n",
    "    return dict_\n",
    "\n",
    "def _concat_columns(dataframe: pd.DataFrame) -> np.ndarray:\n",
    "    if dataframe.shape[0] == 0:\n",
    "        return np.array([], dtype=object)\n",
    "    array = dataframe.iloc[0].values\n",
    "    result = [array]\n",
    "    for i in range(1, dataframe.shape[0]):\n",
    "        curr_array = dataframe.iloc[i].values\n",
    "        result = np.append(result, [curr_array], axis=0)\n",
    "    return result\n",
    "\n",
    "def create_ngrams(sentence: list, sequence_shape: int) -> pd.Series:\n",
    "    if sequence_shape > len(sentence):\n",
    "        return pd.Series(dtype='object')\n",
    "    n_words = len(sentence) - sequence_shape + 1\n",
    "    n_sentence = sentence[:n_words]\n",
    "    ngrams = pd.Series(dtype='object')\n",
    "    for i in range(len(n_sentence)):\n",
    "        ngrams = ngrams.append(pd.Series([sentence[i:i + sequence_shape]]))\n",
    "    ngrams.reset_index(drop=True, inplace=True)\n",
    "    return ngrams\n",
    "\n",
    "def vectorize_text(text: str,\n",
    "                   word_vector_dict: dict,\n",
    "                   vector_shape: int,\n",
    "                   sequence_shape: int) -> np.ndarray:\n",
    "    word_vector_dict = _cut_dict_values(word_vector_dict, vector_shape)\n",
    "    sentence = text.split()\n",
    "    ngrams = create_ngrams(sentence, sequence_shape)\n",
    "    dataframe_ngrams = ngrams.apply(lambda ngram: pd.Series(ngram))\n",
    "    dataframe_vectors = dataframe_ngrams.apply(lambda ngram: ngram.map(word_vector_dict))\n",
    "    result_dataframe = _concat_columns(dataframe_vectors)\n",
    "    return result_dataframe\n",
    "\n",
    "def vectorize_corpus(corpus_array: np.ndarray,\n",
    "                     word_vector_dict: dict,\n",
    "                     vector_shape: int,\n",
    "                     sequence_shape: int) -> list:\n",
    "    result = list()\n",
    "    for text_index in tqdm(range(len(corpus_array))):\n",
    "        vectorized_text = vectorize_text(corpus_array[text_index][0], word_vector_dict,\n",
    "                                         vector_shape, sequence_shape)\n",
    "        result.append(vectorized_text)\n",
    "    return result\n",
    "\n",
    "def vectorize(corpus: str,\n",
    "              word_list: str,\n",
    "              word_vectors: str,\n",
    "              vector_shape: int,\n",
    "              sequence_shape: int) -> np.ndarray:\n",
    "    corpus = pd.read_csv(corpus)\n",
    "    word_list = np.load(word_list)\n",
    "    word_vectors = np.load(word_vectors)\n",
    "    word_vector_dict = dict(zip(word_list, word_vectors))\n",
    "    vectorized_corpus = vectorize_corpus(corpus.values,\n",
    "                                         word_vector_dict,\n",
    "                                         vector_shape,\n",
    "                                         sequence_shape)\n",
    "    return np.array(vectorized_corpus, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf7dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized_corpus = vectorize(CORPUS,\n",
    "                              WORD_LIST,\n",
    "                              WORD_VECTORS,\n",
    "                              VECTOR_SHAPE,\n",
    "                              SEQUENCE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16480be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"EnVectorizedCorpus\", vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e579c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
