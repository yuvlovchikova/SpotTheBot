{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvKLls3Ol-vr"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5203,
     "status": "ok",
     "timestamp": 1641572055118,
     "user": {
      "displayName": "Юлия Ловчикова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01035662716647446064"
     },
     "user_tz": -180
    },
    "id": "CznNTk3VmOLT",
    "outputId": "bce71080-c496-49d9-eb3d-0f89fc4adde4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEMATIZATED_CORPUS = \"EnLemCorpus.csv\"\n",
    "STOPWORDS = \"stopwords-en.json\"\n",
    "STOPWORDS_ADD = [\"a\", \"aa\", \"aaa\", \"aaaa\"]\n",
    "TEXT_SHAPES = [500, 1000, 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYYLljVTmbym"
   },
   "source": [
    "# Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_text(text: str, stop_words: list) -> str:\n",
    "    text_list = text.split()\n",
    "    result_text_list = []\n",
    "    for word in text_list:\n",
    "        if word not in stop_words:\n",
    "            result_text_list.append(word)\n",
    "    return ' '.join(result_text_list)\n",
    "\n",
    "def remove_stop_words(lemmatized_corpus: str, stop_words: str, add_: list) -> pd.DataFrame:\n",
    "    lemmatized_corpus = pd.read_csv(LEMATIZATED_CORPUS)\n",
    "    stop_words = json.load(open(STOPWORDS)) + add_\n",
    "    lambda_ = lambda text: remove_stop_words_text(text, stop_words)\n",
    "    lemmatized_corpus['clean_text'] = lemmatized_corpus['lem_sentence'].apply(lambda_)\n",
    "    return lemmatized_corpus\n",
    "\n",
    "def create_textshape_data(dataframe: pd.DataFrame, text_shape: list, column: str) -> pd.DataFrame:\n",
    "    data_text_shape = pd.DataFrame(columns=['text_shape', 'pages_amount'])\n",
    "    for shape in text_shape:\n",
    "        lambda_ = lambda text: len(text.split()) > shape\n",
    "        pages_amount = dataframe[dataframe[column].apply(lambda_)].shape[0]\n",
    "        data_text_shape = data_text_shape.append({'text_shape': shape,\n",
    "                                                  'pages_amount': pages_amount}, ignore_index=True)\n",
    "    return data_text_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = remove_stop_words(LEMATIZATED_CORPUS, STOPWORDS, STOPWORDS_ADD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_textshape_data(clean_corpus, TEXT_SHAPES, 'clean_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the stop words, we got about the same number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus[['clean_text']].to_csv(\"EnCleanCorpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = pd.read_csv(\"EnCleanCorpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPP2anUoDkp0WgymSGEnT5a",
   "collapsed_sections": [
    "EvKLls3Ol-vr",
    "EYYLljVTmbym"
   ],
   "mount_file_id": "16k9tBMciW7usx9adm1fkWPtKUFoG-jcy",
   "name": "ReadWiki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
