{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvKLls3Ol-vr"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5203,
     "status": "ok",
     "timestamp": 1641572055118,
     "user": {
      "displayName": "Юлия Ловчикова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01035662716647446064"
     },
     "user_tz": -180
    },
    "id": "CznNTk3VmOLT",
    "outputId": "bce71080-c496-49d9-eb3d-0f89fc4adde4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import nltk\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYYLljVTmbym"
   },
   "source": [
    "# Reading texts from English Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1641572059126,
     "user": {
      "displayName": "Юлия Ловчикова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01035662716647446064"
     },
     "user_tz": -180
    },
    "id": "FWlLuaPqmYj9"
   },
   "outputs": [],
   "source": [
    "def _remove_non_printed_chars(string):\n",
    "    \"leave only English letters\"\n",
    "    reg = re.compile('[^a-zA-ZäöåÄÖÅ]')\n",
    "    return reg.sub(' ', string)\n",
    "\n",
    "def _trim_string(string):\n",
    "    \"remove extra spaces, remove trailing spaces, lower the case\"\n",
    "    return re.sub('\\s+', ' ', string).strip().lower()\n",
    "\n",
    "def clean_string(string):\n",
    "    string = _remove_non_printed_chars(string)\n",
    "    string = _trim_string(string)\n",
    "    return string\n",
    "\n",
    "def split_keep_sep(string, sep):\n",
    "    cleaned = []\n",
    "    string = re.split('(%s)' % re.escape(sep), string)\n",
    "    for _ in string:\n",
    "        if _ != '' and _ != sep:\n",
    "            cleaned.append(sep + _)\n",
    "    return cleaned\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def remove_special_chars(text, char_list):\n",
    "    for char in char_list:\n",
    "        text = text.replace(char, '')\n",
    "    return text.replace(u'\\xa0', u' ')\n",
    "\n",
    "def process_wiki_files(wiki_file):\n",
    "    chars = ['\\n']\n",
    "    with open(wiki_file, encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    articles = split_keep_sep(content, '<doc id=')\n",
    "    df = pd.DataFrame(columns=['article_uuid', 'sentence', 'proc_sentence', 'proc_len'])\n",
    "    for article in articles:\n",
    "        uuid = uuid4()\n",
    "        article = remove_special_chars(remove_html_tags(article), chars)\n",
    "        sentences = nltk.sent_tokenize(article)\n",
    "        proc_sentences = [clean_string(sentence) for sentence in sentences]\n",
    "        proc_lens = [len(sentence.split(' ')) for sentence in proc_sentences]\n",
    "        temp_df = pd.DataFrame({'article_uuid': [uuid] * len(sentences),\n",
    "                                'sentence': sentences,\n",
    "                                'proc_sentence': proc_sentences,\n",
    "                                'proc_len': proc_lens})\n",
    "        df = df.append(temp_df)\n",
    "    return df\n",
    "\n",
    "def _apply_lst(args):\n",
    "    params, func, num, kwargs = args\n",
    "    return num, func(*params, **kwargs)\n",
    "\n",
    "def list_multiprocessing(param_lst, func, **kwargs):\n",
    "    if __name__ == '__main__':\n",
    "        workers = kwargs.pop('workers')\n",
    "        with Pool(workers) as p:\n",
    "            apply_lst = [([params], func, i, kwargs) for i, params in enumerate(param_lst)]\n",
    "            result = list(tqdm(p.imap(_apply_lst, apply_lst), total=len(apply_lst)))\n",
    "        result=sorted(result, key=lambda x: x[0])\n",
    "        return [_[1] for _ in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "executionInfo": {
     "elapsed": 18324,
     "status": "error",
     "timestamp": 1641572139725,
     "user": {
      "displayName": "Юлия Ловчикова",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01035662716647446064"
     },
     "user_tz": -180
    },
    "id": "epQrrKOv1T24",
    "outputId": "41004c7b-db6f-429a-b5d8-ccb8075faa2c"
   },
   "outputs": [],
   "source": [
    "wiki_files = []\n",
    "for filename in glob.iglob(\"EnWiki/*/*\", recursive=True):\n",
    "    wiki_files.append(filename)\n",
    "\n",
    "df = list_multiprocessing(wiki_files, process_wiki_files, workers=4)\n",
    "df = pd.concat(df).reset_index(drop=True)\n",
    "df.article_uuid = df.article_uuid.astype(str)\n",
    "df.to_csv(\"EnWikiTexts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EnWikiTexts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPP2anUoDkp0WgymSGEnT5a",
   "collapsed_sections": [
    "EvKLls3Ol-vr",
    "EYYLljVTmbym"
   ],
   "mount_file_id": "16k9tBMciW7usx9adm1fkWPtKUFoG-jcy",
   "name": "ReadWiki.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
