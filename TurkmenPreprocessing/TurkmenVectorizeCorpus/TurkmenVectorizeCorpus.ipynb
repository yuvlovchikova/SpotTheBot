{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87647cf6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SHAPE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3698529",
   "metadata": {},
   "source": [
    "# Vectorize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut_dict_values(input_dict: dict, k: int) -> dict:\n",
    "    lambda_ = lambda value: value[:k]\n",
    "    dict_ = dict(zip(input_dict, map(lambda_, input_dict.values())))\n",
    "    return dict_\n",
    "\n",
    "def vectorize_text(text: str, word_vector_dict: dict, vector_shape: int) -> dict:\n",
    "    word_vector_dict = _cut_dict_values(word_vector_dict, vector_shape)\n",
    "    words = text.split()\n",
    "    vectors = list(map(word_vector_dict.get, words))\n",
    "    text_dict = dict(zip(words, vectors))\n",
    "    return text_dict\n",
    "\n",
    "def vectorize_corpus(corpus_array: list,\n",
    "                     pg_indexes: list,\n",
    "                     word_vector_dict: dict,\n",
    "                     vector_shape: int) -> np.ndarray:\n",
    "    result = list()\n",
    "    current_page_index = -1\n",
    "    sentence_num = 0\n",
    "    for pg_index, sentence in tqdm(zip(pg_indexes, corpus_array), total=len(pg_indexes)):\n",
    "        vectorized_sentence = vectorize_text(sentence, word_vector_dict,\n",
    "                                             vector_shape)\n",
    "        if current_page_index != pg_index:\n",
    "            current_page_index = pg_index\n",
    "            sentence_num = 0\n",
    "        \n",
    "        result.append({'article_index': pg_index,\n",
    "                       'sentence_num': sentence_num,\n",
    "                       'sentence': vectorized_sentence})\n",
    "        sentence_num += 1\n",
    "\n",
    "    return np.array(result, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(\"TurkmenCleanCorpusDotSplit.csv\")\n",
    "word_list = np.load(\"WORD_LIST.npy\")\n",
    "U = np.load(\"U.npy\")\n",
    "Sigma = np.load(\"Sigma.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vectors = np.dot(U, np.diag(Sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b215ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_vector_dict = dict(zip(word_list, words_vectors))\n",
    "vectorized_corpus = vectorize_corpus(corpus['clean_text'].tolist()[:100],\n",
    "                                     corpus['article_index'].tolist()[:100],\n",
    "                                     word_vector_dict,\n",
    "                                     VECTOR_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16480be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"TurkmenVectorizedCorpus\", vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73744b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = lambda vector: vector.tolist()\n",
    "dict_ = dict(zip(word_vector_dict, map(lambda_, word_vector_dict.values())))\n",
    "with open('WordVectorDict.json', 'w') as f:\n",
    "    json.dump(dict_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bd33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
